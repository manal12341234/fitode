%\VignetteEngine{knitr::knitr}
%\VignetteDepends{ggplot2}
%\VignetteDepends{plyr}
%\VignetteDepends{dplyr}
%\VignetteDepends{reshape2}
%\VignetteIndexEntry{Basic ODE model fitting}
\documentclass{article}
\title{Basic ODE fitting}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{hyperref}
\newcommand{\rzero}{{\cal R}_0}
\newcommand{\code}[1]{{\tt #1}}
\newcommand{\bmb}[1]{{\color{blue} bmb: \emph{#1}}}
\bibliographystyle{chicago}
\date{\today}
\begin{document}
\maketitle

<<opts,echo=FALSE>>=
library("knitr")
opts_chunk$set(fig.width=6,fig.height=4)
knit_hooks$set(basefig=function(before, options, envir) {
                   if (before) {
                       par(bty="l",las=1)
                   } else { }
               })
@

\tableofcontents

\section{Preliminaries}

Load packages:

<<pkgs,message=FALSE>>=
library(fitode)
@

\section{Basic fitting}

\subsection{Exponential decay model}

Suppose we have a stock (compartment)
that is losing a fixed \emph{per capita}
fraction per unit time, as in radioactive decay,
financial depreciation, or a pure-death process.

<<expsim>>=
set.seed(123)
true.m <- 0.5
true.A0 <- 200
true.sd <- 15

exp.data <- data.frame(
    x=rep(0:4, 3),
    y=rnorm(15, true.A0 * exp(-true.m * rep(0:4, 3)), sd=true.sd)
)
@

<<expplot,basefig=TRUE>>=
plot(exp.data)
@

The true dynamics can be modeled with the following equation:
$$
\frac{dA}{dt} = - m A
$$

We can translate this into a \code{fitode} model as follows:

<<expmodel>>=
exp.model <- new("model.ode",
    name = "SI",
    model = list(
        A ~ -m * A
    ),
    observation = list(
        y ~ dnorm(mean=A, sd=sd)
    ),
    initial = list(
        A ~ A0
    ),
    par=c("m", "A0", "sd")
)
@

Then, we can fit the model:

<<fitchem>>=
exp.fit <- fitode(
    exp.model,
    exp.data,
    start=c(m=0.5, A0=200, sd=15),
    tcol="x"
)
@

To diagnose the fit, we can use the \code{plot} method for \code{fitode} objects.
\bmb{we should be careful here: in base R the convention is that \code{plot} shows diagnostics (although of course that's different in \code{deSolve}, which plots trajectories).  Do we want to set up different methods for plotting predictions vs trajectories, or should there be an option to \code{plot}?}
By default, this will plot the estimated trajectory along with
95\% confidence intervals, estimated via the delta method.

<<plotexp,basefig=TRUE>>=
plot(exp.fit, level=0.95)
curve(true.A0 * exp(-true.m*x), add=TRUE, lty=1, col="red")
legend(
    x="topright",
    legend=c("estimated", "true"),
    col=c("black", "red"),
    lty=1
)
@

To obtain confidence intervals on the parameters, we can use \code{confint} method.
There are three available methods for obtaining the confidence intervals: \code{delta}, \code{profile} and \code{wmvrnorm}.
Due to computation speed, default option is \code{delta}.
We will get into the details later.
For now,

<<expconf>>=
confint(exp.fit)
@

Since this particular differential equation has a simple closed-form solution ($A(t) = A(0) \exp(-m t)$), we can use the \code{glm} function to fit the model as well (we need to use \code{glm} with the \code{gaussian} family and a log link, rather than \code{lm}, in order to fit an exponential curve with constant residual variance).

<<glmfitexp>>=
glm.fit <- glm(y~x,
    family=gaussian(link="log"),
    data=exp.data,
    start = c(intercept=log(200), x=-0.5))
@

Comparing the results:

<<glmfitpred,basefig=TRUE>>=
glm.pred <- predict(glm.fit, data.frame(x=0:4), se.fit=TRUE, type="response")

glm.data <- data.frame(
    x=0:4,
    estimate=glm.pred$fit,
    lwr=glm.pred$fit-1.96 * glm.pred$se.fit,
    upr=glm.pred$fit+1.96 * glm.pred$se.fit
)

plot(exp.fit, level=0.95)
lines(glm.data$x, glm.data$estimate, col=2)
lines(glm.data$x, glm.data$lwr, col=2)
lines(glm.data$x, glm.data$upr, col=2)
legend(
    x="topright",
    legend=c("estimated (fitode)", "estimated (glm)"),
    col=c("black", "red"),
    lty=1
)
@

The estimated trajectories and their confidence intervals are essentially indistinguishable.

\subsection{Chemical reaction - multiple state fitting}

Now, consider the following chemical reaction:
$$
A \to 3 B
$$
Then, we can write the governing differential equations as follows:
$$
\begin{aligned}
\frac{dA}{dt} &= - k A\\
\frac{dB}{dt} &= 3 k B
\end{aligned}
$$
Suppose we have observed values for both quantities (we assume their
standard deviation is identical):
<<chem_model,echo=FALSE>>=
reaction_model <- new("model.ode",
    name = "reaction",
    model = list(
        A ~ - k * A,
        B ~ 3 * k * A
    ),
    observation = list(
        y1 ~ dnorm(mean=A, sd=sd),
        y2 ~ dnorm(mean=B, sd=sd)
    ),
    initial = list(
        A~A0,
        B~B0
    ),
    par=c("k", "A0", "B0", "sd")
)

true.k <- 0.1
true.A0 <- 300
true.B0 <- 100
true.sd <- 10

times <- 1:20

reaction_run <- ode.solve(reaction_model, times, c(k=true.k, A0=true.A0, B0=true.B0, sd1=true.sd))
reaction_data <- data.frame(
    times=times,
    y1=rnorm(20, reaction_run@solution$A, sd=true.sd),
    y2=rnorm(20, reaction_run@solution$B, sd=true.sd)
)
@

Taking a quick look at the simulation results:
<<simhead>>=
head(reaction_data)
@

Here, \code{y1} measures quantity $A$ and \code{y2} measures quantity $B$.
\bmb{is there a reason not to use names that match the ODE definition?}
Then, we can define the model:

<<reactionmodel>>=
reaction_model <- new("model.ode",
    name = "reaction",
    model = list(
        A ~ - k * A,
        B ~ 3 * k * A
    ),
    observation = list(
        y1 ~ dnorm(mean=A, sd=sd),
        y2 ~ dnorm(mean=B, sd=sd)
    ),
    initial = list(
        A~A0,
        B~B0
    ),
    par=c("k", "A0", "B0", "sd")
)
@

We can fit this using arbitrary starting conditions.

<<reactionfit,cache=TRUE, basefig=TRUE>>=
reaction_fit <- fitode(
    reaction_model,
    reaction_data,
    start=c(k=0.1, A0=300, B0=10, sd=10)
)

plot(reaction_fit, level=0.95)
@

Confidence intervals...

<<expci>>=
confint(reaction_fit)
@

\subsection{Fitting SIR model}

<<sirsetup,basefig=TRUE>>=
harbin <- fitsir::harbin
harbin2 <- rbind(data.frame(week=1, Deaths=NA), harbin)

plot(harbin2)
@

We need to add an \code{NA} observation to make this work...

<<sirfit, warning=FALSE,cache=TRUE>>=
SI_model_c <- new("model.ode",
    name = "SI",
    model = list(
        S ~ - beta*S*I/N,
        I ~ beta*S*I/N - gamma*I,
        cDeath ~ gamma*I
    ),
    observation = list(
        Deaths ~ dnbinom(mu=cDeath, size=size)
    ),
    initial = list(
        S ~ N * (1 - i0),
        I ~ N * i0,
        cDeath ~ 0
    ),
    diffnames="cDeath",
    par=c("beta", "gamma", "N", "i0", "size")
)

start <- c(beta=2, gamma=1, N=20000, i0=1e-5, size=10)

sirfit <- fitode(
    SI_model_c,
    harbin2,
    start=start,
    link = list(
        beta="log",
        gamma="log",
        N="log",
        i0="logit",
        size="log"
    ),
    tcol="week"
)

plot(sirfit, level=0.95)
@

Confidence intervals on various epidemiological quantities:

<<sirci1,cache=TRUE>>=
confint(sirfit,
        parm=list(
            R0~beta/gamma,
            r~beta-gamma
        ),
        method="wmvrnorm")
@

Alternate parameterization:

<<sirfit2, warning=FALSE>>=
SI_model_c2 <- Transform(
    SI_model_c,
    list(
        beta~(R0_1+1)*gamma
    ),
    par=c("R0_1", "gamma", "N", "i0", "size")
)

cc <- coef(sirfit)

start2 <- c(R0_1=unname(cc[1]/cc[2]-1), cc[-1])

sirfit2 <- fitode(
    SI_model_c2,
    harbin2,
    start=start2,
    link = list(
        R0_1="log",
        gamma="log",
        N="log",
        i0="logit",
        size="log"
    ),
    tcol="week"
)

@

Compare fits:

<<sircompplot,basefig=TRUE>>=
plot(sirfit)
plot(sirfit2, add=TRUE, col.traj="red", col.conf="red")
@

We get identical fits. The advantage of this parameterization is that we can obtain profile confidence intervals on R0 (it's a little slow...):

<<sirconf, warning=FALSE,cache=TRUE>>=
set.seed(101)
confint(sirfit2, "R0_1", method="profile") + 1
confint(sirfit2, "R0_1", method="wmvrnorm") + 1
confint(sirfit, parm=list(R0~beta/gamma))
confint(sirfit, parm=list(R0~beta/gamma), method="wmvrnorm")
@

I'm not sure why performing \code{wmvrnorm} on the beta/gamma scale gives narrower confidence intervals. Maybe it's because of the parameterization?

<<sirconfplot>>=
set.seed(101)
plot(sirfit, method="wmvrnorm")
plot(sirfit2, add=TRUE, col.traj="red", col.conf="red", method="wmvrnorm")
@

\end{document}
